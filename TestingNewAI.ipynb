{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import ndarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self,inputAmnt,outputAmnt):\n",
    "        def sharmaAct(input):\n",
    "            x = input\n",
    "            mask1 = x < -0.5\n",
    "            mask2 = (-0.5 <= x) & (x <= 0.5)\n",
    "\n",
    "            result = np.zeros_like(x)  # Initialize an array of zeros\n",
    "            result[mask1] = (x[mask1] + 1.5) / np.sqrt(np.e)\n",
    "            result[mask2] = np.exp(x[mask2])\n",
    "            result[~(mask1 | mask2)] = x[~(mask1 | mask2)] + 1\n",
    "            return result\n",
    "        def sharmaActPrime(input):\n",
    "            x = input\n",
    "            mask1 = x < -0.5\n",
    "            mask2 = (-0.5 <= x) & (x <= 0.5)\n",
    "            \n",
    "            result = np.zeros_like(x)  # Initialize an array of zeros\n",
    "            result[mask1] =  1 / np.sqrt(np.e) \n",
    "            result[mask2] = np.exp(x[mask2])\n",
    "            result[~(mask1 | mask2)] = 1 \n",
    "            return result\n",
    "        self.f = sharmaAct\n",
    "        self.fPrime = sharmaActPrime\n",
    "        self.w = np.random.uniform(low=-1,high=1,size=(outputAmnt,inputAmnt))\n",
    "        self.b = np.random.uniform(low=-1,high=1,size=(outputAmnt,1))\n",
    "        self.linearCombo = 0\n",
    "        self.input = 0\n",
    "    def compute(self,input):\n",
    "        self.input = input\n",
    "        self.linearCombo = self.w @ input + self.b\n",
    "        return self.f(self.linearCombo)\n",
    "    def compPrime(self):\n",
    "        return self.fPrime(self.linearCombo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inputLayer:\n",
    "    def __init__(self,activation):\n",
    "        def relu(input):\n",
    "            return np.maximum(input,0)\n",
    "        def reluPrime(input):\n",
    "            return np.greater(input, 0).astype(np.float32)\n",
    "        def sigmoid(input):\n",
    "            return 1/(1+np.exp(-input))\n",
    "        def sigmoidPrime(input):\n",
    "            return -np.exp(-input)/(1+np.exp(input))\n",
    "        def tanhPrime(input):\n",
    "            np.power(1/(np.cosh(input)),2)\n",
    "        def sharmaAct(input):\n",
    "            x = input\n",
    "            mask1 = x < -0.5\n",
    "            mask2 = (-0.5 <= x) & (x <= 0.5)\n",
    "\n",
    "            result = np.zeros_like(x)  # Initialize an array of zeros\n",
    "            result[mask1] = (x[mask1] + 1.5) / np.sqrt(np.e)\n",
    "            result[mask2] = np.exp(x[mask2])\n",
    "            result[~(mask1 | mask2)] = x[~(mask1 | mask2)] + 1\n",
    "            return result\n",
    "        def sharmaActPrime(input):\n",
    "            x = input\n",
    "            mask1 = x < -0.5\n",
    "            mask2 = (-0.5 <= x) & (x <= 0.5)\n",
    "            \n",
    "            result = np.zeros_like(x)  # Initialize an array of zeros\n",
    "            result[mask1] =  1 / np.sqrt(np.e) \n",
    "            result[mask2] = np.exp(x[mask2])\n",
    "            result[~(mask1 | mask2)] = 1 \n",
    "            return result\n",
    "        val = {\"relu\":[relu,reluPrime],\"sigmoid\":[sigmoid,sigmoidPrime],\"tanh\":[np.tanh,tanhPrime],'sharma':[sharmaAct,sharmaActPrime]}\n",
    "        self.f = val[activation][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    def __init__(self,input: inputLayer,*layers):\n",
    "        self.layers = list(layers)\n",
    "        self.input = input\n",
    "    def divideByThing(self,input):\n",
    "        if(np.sum(np.abs(input)) == 0):\n",
    "            return input\n",
    "        return input/np.sum(np.abs(input))\n",
    "    def predict(self,input):\n",
    "        output = self.input.f(input)\n",
    "        for k in self.layers:\n",
    "            output = k.compute(output)\n",
    "        return np.apply_along_axis(self.divideByThing,0,output)\n",
    "    #all in 1 gradient descent using some stuff\n",
    "    def gradientDescent(self,inputMat,outputMat):\n",
    "        out = self.predict(inputMat)\n",
    "        godMat = np.identity(n = len(self.layers[-1].w))\n",
    "        chainRes = 2 * (out-outputMat) * self.layers[-1].compPrime()\n",
    "        self.layers.reverse()\n",
    "        prevW = -1\n",
    "        for k in self.layers:\n",
    "                if(not isinstance(prevW,int)):\n",
    "                    godMat = godMat @ prevW\n",
    "                    chainRes *= godMat @ k.compPrime()\n",
    "                \n",
    "                val = np.transpose(godMat) @ chainRes\n",
    "                prevW = k.w                \n",
    "                k.b -= val @ np.ones(shape=(val.shape[1],1))\n",
    "                \n",
    "\n",
    "        self.layers.reverse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333333 0.4       ]\n",
      " [0.66666667 0.6       ]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2],[2,3]])\n",
    "def divideByThing(input):\n",
    "        if(np.sum(np.abs(input)) == 0):\n",
    "            return input\n",
    "        return input/np.sum(np.abs(input))\n",
    "def har(input):\n",
    "      return np.apply_along_axis(divideByThing,0,input)\n",
    "print(har(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "def encode(input):\n",
    "    z = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "    z[input] = 1\n",
    "    return z\n",
    "# Flatten the images\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)  # input for training\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)  # input for testing\n",
    "y_train = y_train.reshape(1,60_000)\n",
    "output_test = np.apply_along_axis(encode,0,y_train)\n",
    "x_train = np.transpose(x_train)\n",
    "realTrain = x_train.reshape(-1,784,1)\n",
    "realYTrain = np.transpose(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = ANN(inputLayer('sharma'),Layer(784,15),Layer(15,10))\n",
    "model.gradientDescent(x_train,output_test)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09914999999999996\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def percentAcc(mod):\n",
    "  global realTrain,realYTrain\n",
    "  error= 0\n",
    "  \n",
    "  for (input,output) in zip(realTrain,realYTrain):\n",
    "    if(np.argmax(mod.predict(input)) != (output)):\n",
    "      error += 1\n",
    "  return 1-(error)/60_000\n",
    "print(percentAcc(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3 4]\n",
      " [3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2,3],[1,2,3]])\n",
    "y = np.array([[1],[2]])\n",
    "print(x+y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
