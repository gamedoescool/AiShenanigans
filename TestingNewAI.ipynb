{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from numpy import ndarray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self,inputAmnt,outputAmnt):\n",
    "        def sharmaAct(input):\n",
    "            x = input\n",
    "            mask1 = x < -0.5\n",
    "            mask2 = (-0.5 <= x) & (x <= 0.5)\n",
    "\n",
    "            result = np.zeros_like(x)  # Initialize an array of zeros\n",
    "            result[mask1] = (x[mask1] + 1.5) / np.sqrt(np.e)\n",
    "            result[mask2] = np.exp(x[mask2])\n",
    "            result[~(mask1 | mask2)] = x[~(mask1 | mask2)] + 1\n",
    "            return result\n",
    "        def sharmaActPrime(input):\n",
    "            x = input\n",
    "            mask1 = x < -0.5\n",
    "            mask2 = (-0.5 <= x) & (x <= 0.5)\n",
    "            \n",
    "            result = np.zeros_like(x)  # Initialize an array of zeros\n",
    "            result[mask1] =  1 / np.sqrt(np.e) \n",
    "            result[mask2] = np.exp(x[mask2])\n",
    "            result[~(mask1 | mask2)] = 1 \n",
    "            return result\n",
    "        self.f = sharmaAct\n",
    "        self.fPrime = sharmaActPrime\n",
    "        self.w = np.random.uniform(low=-1,high=1,size=(outputAmnt,inputAmnt))\n",
    "        self.b = np.random.uniform(low=-1,high=1,size=(outputAmnt,1))\n",
    "        self.linearCombo = 0\n",
    "        self.input = 0\n",
    "    def compute(self,input):\n",
    "        self.input = input\n",
    "        self.linearCombo = self.w @ input + self.b\n",
    "        return self.f(self.linearCombo)\n",
    "    def compPrime(self):\n",
    "        return self.fPrime(self.linearCombo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inputLayer:\n",
    "    def __init__(self,activation):\n",
    "        def relu(input):\n",
    "            return np.maximum(input,0)\n",
    "        def reluPrime(input):\n",
    "            return np.greater(input, 0).astype(np.float32)\n",
    "        def sigmoid(input):\n",
    "            return 1/(1+np.exp(-input))\n",
    "        def sigmoidPrime(input):\n",
    "            return -np.exp(-input)/(1+np.exp(input))\n",
    "        def tanhPrime(input):\n",
    "            np.power(1/(np.cosh(input)),2)\n",
    "        def sharmaAct(input):\n",
    "            x = input\n",
    "            mask1 = x < -0.5\n",
    "            mask2 = (-0.5 <= x) & (x <= 0.5)\n",
    "\n",
    "            result = np.zeros_like(x)  # Initialize an array of zeros\n",
    "            result[mask1] = (x[mask1] + 1.5) / np.sqrt(np.e)\n",
    "            result[mask2] = np.exp(x[mask2])\n",
    "            result[~(mask1 | mask2)] = x[~(mask1 | mask2)] + 1\n",
    "            return result\n",
    "        def sharmaActPrime(input):\n",
    "            x = input\n",
    "            mask1 = x < -0.5\n",
    "            mask2 = (-0.5 <= x) & (x <= 0.5)\n",
    "            \n",
    "            result = np.zeros_like(x)  # Initialize an array of zeros\n",
    "            result[mask1] =  1 / np.sqrt(np.e) \n",
    "            result[mask2] = np.exp(x[mask2])\n",
    "            result[~(mask1 | mask2)] = 1 \n",
    "            return result\n",
    "        val = {\"relu\":[relu,reluPrime],\"sigmoid\":[sigmoid,sigmoidPrime],\"tanh\":[np.tanh,tanhPrime],'sharma':[sharmaAct,sharmaActPrime]}\n",
    "        self.f = val[activation][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    def __init__(self,input: inputLayer,*layers):\n",
    "        self.layers = list(layers)\n",
    "        self.input = input\n",
    "    def divideByThing(self,input):\n",
    "        if(np.sum(np.abs(input)) == 0):\n",
    "            return input\n",
    "        return input/np.sum(np.abs(input))\n",
    "    def predict(self,input):\n",
    "        output = self.input.f(input)\n",
    "        for k in self.layers:\n",
    "            output = k.compute(output)\n",
    "        return np.apply_along_axis(self.divideByThing,0,output)\n",
    "    #all in 1 gradient descent using some stuff\n",
    "    def gradientDescent(self,inputMat,outputMat):\n",
    "        out = self.predict(inputMat)\n",
    "        godMat = np.identity(n = len(self.layers[-1].w))\n",
    "        chainRes = 2 * (out-outputMat) * self.layers[-1].compPrime()\n",
    "        self.layers.reverse()\n",
    "        prevW = -1\n",
    "        for k in self.layers:\n",
    "                if(not isinstance(prevW,int)):\n",
    "                    godMat = godMat @ prevW\n",
    "                    chainRes *= godMat @ k.compPrime()\n",
    "                val = np.transpose(godMat) @ chainRes                 \n",
    "                prevW = k.w\n",
    "                k.b -= val @ np.ones(shape=(val.shape[1],1))\n",
    "\n",
    "        self.layers.reverse()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333333 0.4       ]\n",
      " [0.66666667 0.6       ]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2],[2,3]])\n",
    "def divideByThing(input):\n",
    "        if(np.sum(np.abs(input)) == 0):\n",
    "            return input\n",
    "        return input/np.sum(np.abs(input))\n",
    "def har(input):\n",
    "      return np.apply_along_axis(divideByThing,0,input)\n",
    "print(har(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "def encode(input):\n",
    "    z = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
    "    z[input] = 1\n",
    "    return z\n",
    "# Flatten the images\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)/255  # input for training\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)/255  # input for testing\n",
    "y_train = y_train.reshape(1,60_000)\n",
    "output_test = np.apply_along_axis(encode,0,y_train)\n",
    "x_train = np.transpose(x_train)\n",
    "realTrain = x_train.reshape(-1,784,1)\n",
    "realYTrain = np.transpose(y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANN(inputLayer('sharma'),Layer(784,15),Layer(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gradientDescent(x_train,output_test)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def percentAcc(mod):\n",
    "  global realTrain,realYTrain\n",
    "  error= 0\n",
    "  \n",
    "  for (input,output) in zip(realTrain,realYTrain):\n",
    "    if(np.argmax(mod.predict(input)) != (output)):\n",
    "      error += 1\n",
    "  return 1-(error)/60_000\n",
    "print(percentAcc(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Field elements must be 2- or 3-tuples, got '4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m8\u001b[39m],[\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m])\n\u001b[0;32m      3\u001b[0m np\u001b[38;5;241m.\u001b[39meinsum(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi,j->ij\u001b[39m\u001b[38;5;124m\"\u001b[39m,x,y)\n",
      "\u001b[1;31mTypeError\u001b[0m: Field elements must be 2- or 3-tuples, got '4'"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3])\n",
    "y = np.array([0,4,8])\n",
    "np.einsum(\"i,j->ij\",x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0],\n",
       "       [ 4,  8, 12],\n",
       "       [ 8, 16, 24]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum(\"i,j->ij\",y,x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
